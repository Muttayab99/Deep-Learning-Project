{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:06:04.445365Z",
     "iopub.status.busy": "2025-11-29T22:06:04.444745Z",
     "iopub.status.idle": "2025-11-29T22:06:19.623124Z",
     "shell.execute_reply": "2025-11-29T22:06:19.622217Z",
     "shell.execute_reply.started": "2025-11-29T22:06:04.445340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 22:06:05.653499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764453965.818538      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764453965.864483      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 1: Setup\n",
    "# =======================\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import (\n",
    "    ResNet50, DenseNet121, MobileNet, InceptionV3\n",
    ")\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_pre\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_pre\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_pre\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Original Kaggle dataset path (matches your screenshot)\n",
    "BASE_DATASET_DIR = Path(\"/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake\")\n",
    "TEST_REAL_DIR = BASE_DATASET_DIR / \"test\" / \"real\"\n",
    "TEST_FAKE_DIR = BASE_DATASET_DIR / \"test\" / \"fake\"\n",
    "\n",
    "# Our custom 20k_gan_8_1_1 dataset root\n",
    "TARGET_ROOT = Path(\"/kaggle/working/20k_gan_8_1_1\")\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:06:38.358885Z",
     "iopub.status.busy": "2025-11-29T22:06:38.357859Z",
     "iopub.status.idle": "2025-11-29T22:08:51.945241Z",
     "shell.execute_reply": "2025-11-29T22:08:51.944498Z",
     "shell.execute_reply.started": "2025-11-29T22:06:38.358856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom dataset created at: /kaggle/working/20k_gan_8_1_1\n",
      "train/real: 8000 images\n",
      "train/fake: 8000 images\n",
      "val/real: 1000 images\n",
      "val/fake: 1000 images\n",
      "test/real: 1000 images\n",
      "test/fake: 1000 images\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 2: Create 20k_gan_8_1_1 split\n",
    "# =======================\n",
    "\n",
    "def make_empty_dir_structure(root: Path):\n",
    "    if root.exists():\n",
    "        shutil.rmtree(root)\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for cls in [\"real\", \"fake\"]:\n",
    "            (root / split / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "make_empty_dir_structure(TARGET_ROOT)\n",
    "\n",
    "def sample_and_split(class_dir: Path, n_total: int, splits=(0.8, 0.1, 0.1)):\n",
    "    \"\"\"Return lists of filenames for train, val, test for a given class.\"\"\"\n",
    "    all_images = [str(p) for p in class_dir.glob(\"*.jpg\")] + \\\n",
    "                 [str(p) for p in class_dir.glob(\"*.png\")] + \\\n",
    "                 [str(p) for p in class_dir.glob(\"*.jpeg\")]\n",
    "    all_images = sorted(all_images)\n",
    "    assert len(all_images) >= n_total, f\"Not enough images in {class_dir}\"\n",
    "\n",
    "    random.shuffle(all_images)\n",
    "    all_images = all_images[:n_total]\n",
    "\n",
    "    n_train = int(n_total * splits[0])\n",
    "    n_val   = int(n_total * splits[1])\n",
    "    n_test  = n_total - n_train - n_val\n",
    "\n",
    "    train_files = all_images[:n_train]\n",
    "    val_files   = all_images[n_train:n_train+n_val]\n",
    "    test_files  = all_images[n_train+n_val:]\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "# Sample 10k real + 10k fake from TEST folder\n",
    "REAL_TRAIN, REAL_VAL, REAL_TEST = sample_and_split(TEST_REAL_DIR, 10000)\n",
    "FAKE_TRAIN, FAKE_VAL, FAKE_TEST = sample_and_split(TEST_FAKE_DIR, 10000)\n",
    "\n",
    "def copy_files(file_list, dst_dir: Path):\n",
    "    for src in file_list:\n",
    "        dst = dst_dir / Path(src).name\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "# Copy into our new structure\n",
    "copy_files(REAL_TRAIN, TARGET_ROOT / \"train\" / \"real\")\n",
    "copy_files(REAL_VAL,   TARGET_ROOT / \"val\" / \"real\")\n",
    "copy_files(REAL_TEST,  TARGET_ROOT / \"test\" / \"real\")\n",
    "\n",
    "copy_files(FAKE_TRAIN, TARGET_ROOT / \"train\" / \"fake\")\n",
    "copy_files(FAKE_VAL,   TARGET_ROOT / \"val\" / \"fake\")\n",
    "copy_files(FAKE_TEST,  TARGET_ROOT / \"test\" / \"fake\")\n",
    "\n",
    "print(\"Custom dataset created at:\", TARGET_ROOT)\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"real\", \"fake\"]:\n",
    "        count = len(list((TARGET_ROOT / split / cls).glob(\"*\")))\n",
    "        print(f\"{split}/{cls}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:09:53.400736Z",
     "iopub.status.busy": "2025-11-29T22:09:53.400409Z",
     "iopub.status.idle": "2025-11-29T22:09:53.602691Z",
     "shell.execute_reply": "2025-11-29T22:09:53.601920Z",
     "shell.execute_reply.started": "2025-11-29T22:09:53.400712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16000, 2000, 2000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 3: Data generators\n",
    "# =======================\n",
    "\n",
    "def build_generators(root_dir: Path, preprocess_func=None, shuffle_train=True):\n",
    "    \"\"\"\n",
    "    Returns (train_gen, val_gen, test_gen).\n",
    "    If preprocess_func is None → rescale 1./255.\n",
    "    Otherwise uses given preprocess function (for transfer learning models).\n",
    "    \"\"\"\n",
    "    if preprocess_func is None:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        val_datagen   = ImageDataGenerator(rescale=1./255.)\n",
    "        test_datagen  = ImageDataGenerator(rescale=1./255.)\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "        val_datagen   = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "        test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        directory=str(root_dir / \"train\"),\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=shuffle_train,\n",
    "        seed=SEED\n",
    "    )\n",
    "    val_gen = val_datagen.flow_from_directory(\n",
    "        directory=str(root_dir / \"val\"),\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False\n",
    "    )\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        directory=str(root_dir / \"test\"),\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "# Generators for the custom CNN (simple rescaling)\n",
    "train_gen_cnn, val_gen_cnn, test_gen_cnn = build_generators(TARGET_ROOT, preprocess_func=None)\n",
    "\n",
    "len(train_gen_cnn.filenames), len(val_gen_cnn.filenames), len(test_gen_cnn.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:10:06.488975Z",
     "iopub.status.busy": "2025-11-29T22:10:06.488678Z",
     "iopub.status.idle": "2025-11-29T22:10:06.495198Z",
     "shell.execute_reply": "2025-11-29T22:10:06.494442Z",
     "shell.execute_reply.started": "2025-11-29T22:10:06.488954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Cell 4: Train & evaluate helper\n",
    "# =======================\n",
    "\n",
    "def train_and_evaluate(model, train_gen, val_gen, test_gen,\n",
    "                       epochs, model_name=\"model\"):\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_accuracy\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_gen, verbose=1)\n",
    "    print(f\"\\n[{model_name}] Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Detailed metrics\n",
    "    test_gen.reset()\n",
    "    preds = model.predict(test_gen, verbose=1)\n",
    "    y_pred = (preds.ravel() >= 0.5).astype(int)\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"fake\", \"real\"]))\n",
    "\n",
    "    return history, (test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:39:32.771979Z",
     "iopub.status.busy": "2025-11-29T22:39:32.771324Z",
     "iopub.status.idle": "2025-11-29T22:39:32.777931Z",
     "shell.execute_reply": "2025-11-29T22:39:32.776985Z",
     "shell.execute_reply.started": "2025-11-29T22:39:32.771953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Extra helper for fixed-epoch training (no EarlyStopping)\n",
    "# =======================\n",
    "\n",
    "def train_and_evaluate_no_es(model, train_gen, val_gen, test_gen,\n",
    "                             epochs, model_name=\"model\"):\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_gen, verbose=1)\n",
    "    print(f\"\\n[{model_name}] Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Detailed metrics\n",
    "    test_gen.reset()\n",
    "    preds = model.predict(test_gen, verbose=1)\n",
    "    y_pred = (preds.ravel() >= 0.5).astype(int)\n",
    "    y_true = test_gen.classes\n",
    "\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"fake\", \"real\"]))\n",
    "\n",
    "    return history, (test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T22:14:55.877235Z",
     "iopub.status.busy": "2025-11-29T22:14:55.876871Z",
     "iopub.status.idle": "2025-11-29T22:14:55.883289Z",
     "shell.execute_reply": "2025-11-29T22:14:55.882508Z",
     "shell.execute_reply.started": "2025-11-29T22:14:55.877210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Cell 6: Transfer-learning model builder\n",
    "# =======================\n",
    "\n",
    "def build_transfer_model(base_constructor, input_shape=(256, 256, 3), name=\"TLModel\"):\n",
    "    \"\"\"\n",
    "    base_constructor: Keras application (ResNet50, DenseNet121, MobileNet, InceptionV3)\n",
    "    \"\"\"\n",
    "    base_model = base_constructor(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    # Feature extractor only (as in the paper)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=name)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T23:00:29.944055Z",
     "iopub.status.busy": "2025-11-29T23:00:29.943440Z",
     "iopub.status.idle": "2025-11-29T23:24:36.595850Z",
     "shell.execute_reply": "2025-11-29T23:24:36.595269Z",
     "shell.execute_reply.started": "2025-11-29T23:00:29.944031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "=== Phase 1: train head only (8 epochs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,589,761</span> (89.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,589,761\u001b[0m (89.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> (8.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,049\u001b[0m (8.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 131ms/step - accuracy: 0.6603 - loss: 0.6347 - val_accuracy: 0.8100 - val_loss: 0.4330\n",
      "Epoch 2/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 120ms/step - accuracy: 0.7742 - loss: 0.4726 - val_accuracy: 0.8445 - val_loss: 0.3853\n",
      "Epoch 3/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 119ms/step - accuracy: 0.7857 - loss: 0.4512 - val_accuracy: 0.8445 - val_loss: 0.3710\n",
      "Epoch 4/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 120ms/step - accuracy: 0.7904 - loss: 0.4456 - val_accuracy: 0.8525 - val_loss: 0.3602\n",
      "Epoch 5/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 119ms/step - accuracy: 0.8032 - loss: 0.4277 - val_accuracy: 0.8560 - val_loss: 0.3525\n",
      "Epoch 6/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 119ms/step - accuracy: 0.8128 - loss: 0.4147 - val_accuracy: 0.8680 - val_loss: 0.3403\n",
      "Epoch 7/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 119ms/step - accuracy: 0.8056 - loss: 0.4319 - val_accuracy: 0.8675 - val_loss: 0.3383\n",
      "Epoch 8/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 120ms/step - accuracy: 0.8047 - loss: 0.4263 - val_accuracy: 0.8625 - val_loss: 0.3425\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.8512 - loss: 0.3749\n",
      "\n",
      "[ResNet50_phase1] Test accuracy: 0.8600, Test loss: 0.3443\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 157ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[858 142]\n",
      " [138 862]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.86      0.86      0.86      1000\n",
      "        real       0.86      0.86      0.86      1000\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "\n",
      "=== Phase 2: fine-tune top ResNet layers (max 24 epochs) ===\n",
      "0 conv4_block6_1_relu frozen\n",
      "1 conv4_block6_2_conv frozen\n",
      "2 conv4_block6_2_bn frozen\n",
      "3 conv4_block6_2_relu frozen\n",
      "4 conv4_block6_3_conv frozen\n",
      "5 conv4_block6_3_bn frozen\n",
      "6 conv4_block6_add frozen\n",
      "7 conv4_block6_out frozen\n",
      "8 conv5_block1_1_conv frozen\n",
      "9 conv5_block1_1_bn frozen\n",
      "10 conv5_block1_1_relu trainable\n",
      "11 conv5_block1_2_conv trainable\n",
      "12 conv5_block1_2_bn frozen\n",
      "13 conv5_block1_2_relu trainable\n",
      "14 conv5_block1_0_conv trainable\n",
      "15 conv5_block1_3_conv trainable\n",
      "16 conv5_block1_0_bn frozen\n",
      "17 conv5_block1_3_bn frozen\n",
      "18 conv5_block1_add trainable\n",
      "19 conv5_block1_out trainable\n",
      "20 conv5_block2_1_conv trainable\n",
      "21 conv5_block2_1_bn frozen\n",
      "22 conv5_block2_1_relu trainable\n",
      "23 conv5_block2_2_conv trainable\n",
      "24 conv5_block2_2_bn frozen\n",
      "25 conv5_block2_2_relu trainable\n",
      "26 conv5_block2_3_conv trainable\n",
      "27 conv5_block2_3_bn frozen\n",
      "28 conv5_block2_add trainable\n",
      "29 conv5_block2_out trainable\n",
      "30 conv5_block3_1_conv trainable\n",
      "31 conv5_block3_1_bn frozen\n",
      "32 conv5_block3_1_relu trainable\n",
      "33 conv5_block3_2_conv trainable\n",
      "34 conv5_block3_2_bn frozen\n",
      "35 conv5_block3_2_relu trainable\n",
      "36 conv5_block3_3_conv trainable\n",
      "37 conv5_block3_3_bn frozen\n",
      "38 conv5_block3_add trainable\n",
      "39 conv5_block3_out trainable\n",
      "Epoch 1/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 175ms/step - accuracy: 0.8269 - loss: 0.3854 - val_accuracy: 0.9090 - val_loss: 0.2337 - learning_rate: 1.0000e-05\n",
      "Epoch 2/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 163ms/step - accuracy: 0.9095 - loss: 0.2194 - val_accuracy: 0.9380 - val_loss: 0.1609 - learning_rate: 1.0000e-05\n",
      "Epoch 3/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9611 - loss: 0.1018 - val_accuracy: 0.9450 - val_loss: 0.1449 - learning_rate: 1.0000e-05\n",
      "Epoch 4/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9809 - loss: 0.0511 - val_accuracy: 0.9545 - val_loss: 0.1328 - learning_rate: 1.0000e-05\n",
      "Epoch 5/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9926 - loss: 0.0208 - val_accuracy: 0.9505 - val_loss: 0.1536 - learning_rate: 1.0000e-05\n",
      "Epoch 6/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9938 - loss: 0.0188\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9565 - val_loss: 0.1386 - learning_rate: 1.0000e-05\n",
      "Epoch 7/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9981 - loss: 0.0066 - val_accuracy: 0.9640 - val_loss: 0.1461 - learning_rate: 5.0000e-06\n",
      "Epoch 8/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9993 - loss: 0.0028\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9660 - val_loss: 0.1386 - learning_rate: 5.0000e-06\n",
      "Epoch 9/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9645 - val_loss: 0.1532 - learning_rate: 2.5000e-06\n",
      "Epoch 10/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9999 - loss: 9.7605e-04\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9999 - loss: 9.7626e-04 - val_accuracy: 0.9625 - val_loss: 0.1702 - learning_rate: 2.5000e-06\n",
      "Epoch 11/24\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 162ms/step - accuracy: 0.9998 - loss: 8.6502e-04 - val_accuracy: 0.9640 - val_loss: 0.1666 - learning_rate: 1.2500e-06\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.9557 - loss: 0.1783\n",
      "\n",
      "[ResNet50_finetuned] Test accuracy: 0.9650, Test loss: 0.1362\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[954  46]\n",
      " [ 24 976]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.98      0.95      0.96      1000\n",
      "        real       0.95      0.98      0.97      1000\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.97      0.96      0.96      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13615216314792633, 0.9649999737739563)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 7: ResNet50 with 32 epochs total (8 + 24) and fine-tuning\n",
    "# =======================\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Generators with ResNet preprocessing\n",
    "train_res, val_res, test_res = build_generators(TARGET_ROOT, preprocess_func=resnet_pre)\n",
    "\n",
    "# Build base ResNet50\n",
    "base_model_resnet = ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Phase 1 – train new head only (8 epochs)\n",
    "# -------------------------\n",
    "base_model_resnet.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(256, 256, 3))\n",
    "x = base_model_resnet(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "resnet_model = models.Model(inputs, outputs, name=\"ResNet50_model\")\n",
    "\n",
    "# Slightly higher LR since we’re only training a small head\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"=== Phase 1: train head only (8 epochs) ===\")\n",
    "resnet_model.summary()\n",
    "\n",
    "history_resnet_p1, _ = train_and_evaluate_no_es(\n",
    "    resnet_model,\n",
    "    train_res,\n",
    "    val_res,\n",
    "    test_res,\n",
    "    epochs=8,\n",
    "    model_name=\"ResNet50_phase1\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Phase 2 – fine-tune top ResNet layers (up to 24 epochs)\n",
    "# -------------------------\n",
    "\n",
    "# Unfreeze last ~30 layers (except BatchNorm, which we keep frozen)\n",
    "for layer in base_model_resnet.layers[-30:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Much lower LR for fine-tuning\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Phase 2: fine-tune top ResNet layers (max 24 epochs) ===\")\n",
    "for i, layer in enumerate(base_model_resnet.layers[-40:]):\n",
    "    print(i, layer.name, \"trainable\" if layer.trainable else \"frozen\")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_resnet_p2 = resnet_model.fit(\n",
    "    train_res,\n",
    "    epochs=24,                 # upper cap; EarlyStopping will usually stop earlier\n",
    "    validation_data=val_res,\n",
    "    callbacks=[early, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Final evaluation on test set\n",
    "# -------------------------\n",
    "test_loss, test_acc = resnet_model.evaluate(test_res, verbose=1)\n",
    "print(f\"\\n[ResNet50_finetuned] Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Detailed metrics\n",
    "test_res.reset()\n",
    "preds = resnet_model.predict(test_res, verbose=1)\n",
    "y_pred = (preds.ravel() >= 0.5).astype(int)\n",
    "y_true = test_res.classes\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"fake\", \"real\"]))\n",
    "\n",
    "test_metrics_resnet = (test_loss, test_acc)\n",
    "test_metrics_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T23:47:09.119347Z",
     "iopub.status.busy": "2025-11-29T23:47:09.118595Z",
     "iopub.status.idle": "2025-11-30T00:15:23.386762Z",
     "shell.execute_reply": "2025-11-30T00:15:23.386159Z",
     "shell.execute_reply.started": "2025-11-29T23:47:09.119322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "=== Phase 1: DenseNet121 head training (8 epochs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DenseNet121_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DenseNet121_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,038,529</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,038,529\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,025\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 130ms/step - accuracy: 0.6107 - loss: 0.6916 - val_accuracy: 0.7930 - val_loss: 0.5086\n",
      "Epoch 2/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 103ms/step - accuracy: 0.7111 - loss: 0.5632 - val_accuracy: 0.7890 - val_loss: 0.4797\n",
      "Epoch 3/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.7276 - loss: 0.5422 - val_accuracy: 0.8090 - val_loss: 0.4603\n",
      "Epoch 4/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 102ms/step - accuracy: 0.7333 - loss: 0.5347 - val_accuracy: 0.8060 - val_loss: 0.4582\n",
      "Epoch 5/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.7283 - loss: 0.5324 - val_accuracy: 0.8230 - val_loss: 0.4510\n",
      "Epoch 6/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.7347 - loss: 0.5311 - val_accuracy: 0.8190 - val_loss: 0.4504\n",
      "Epoch 7/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.7417 - loss: 0.5198 - val_accuracy: 0.8240 - val_loss: 0.4411\n",
      "Epoch 8/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.7285 - loss: 0.5376 - val_accuracy: 0.8210 - val_loss: 0.4429\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.8403 - loss: 0.4457\n",
      "\n",
      "[DenseNet121_phase1] Test accuracy: 0.8095, Test loss: 0.4550\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 228ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[846 154]\n",
      " [227 773]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.79      0.85      0.82      1000\n",
      "        real       0.83      0.77      0.80      1000\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.81      0.81      0.81      2000\n",
      "\n",
      "\n",
      "=== Phase 2: Fine-tuning DenseNet121 (max 25 epochs) ===\n",
      "0 conv5_block4_1_bn frozen\n",
      "1 conv5_block4_1_relu frozen\n",
      "2 conv5_block4_2_conv frozen\n",
      "3 conv5_block4_concat frozen\n",
      "4 conv5_block5_0_bn frozen\n",
      "5 conv5_block5_0_relu frozen\n",
      "6 conv5_block5_1_conv frozen\n",
      "7 conv5_block5_1_bn frozen\n",
      "8 conv5_block5_1_relu frozen\n",
      "9 conv5_block5_2_conv frozen\n",
      "10 conv5_block5_concat trainable\n",
      "11 conv5_block6_0_bn frozen\n",
      "12 conv5_block6_0_relu trainable\n",
      "13 conv5_block6_1_conv trainable\n",
      "14 conv5_block6_1_bn frozen\n",
      "15 conv5_block6_1_relu trainable\n",
      "16 conv5_block6_2_conv trainable\n",
      "17 conv5_block6_concat trainable\n",
      "18 conv5_block7_0_bn frozen\n",
      "19 conv5_block7_0_relu trainable\n",
      "20 conv5_block7_1_conv trainable\n",
      "21 conv5_block7_1_bn frozen\n",
      "22 conv5_block7_1_relu trainable\n",
      "23 conv5_block7_2_conv trainable\n",
      "24 conv5_block7_concat trainable\n",
      "25 conv5_block8_0_bn frozen\n",
      "26 conv5_block8_0_relu trainable\n",
      "27 conv5_block8_1_conv trainable\n",
      "28 conv5_block8_1_bn frozen\n",
      "29 conv5_block8_1_relu trainable\n",
      "30 conv5_block8_2_conv trainable\n",
      "31 conv5_block8_concat trainable\n",
      "32 conv5_block9_0_bn frozen\n",
      "33 conv5_block9_0_relu trainable\n",
      "34 conv5_block9_1_conv trainable\n",
      "35 conv5_block9_1_bn frozen\n",
      "36 conv5_block9_1_relu trainable\n",
      "37 conv5_block9_2_conv trainable\n",
      "38 conv5_block9_concat trainable\n",
      "39 conv5_block10_0_bn frozen\n",
      "40 conv5_block10_0_relu trainable\n",
      "41 conv5_block10_1_conv trainable\n",
      "42 conv5_block10_1_bn frozen\n",
      "43 conv5_block10_1_relu trainable\n",
      "44 conv5_block10_2_conv trainable\n",
      "45 conv5_block10_concat trainable\n",
      "46 conv5_block11_0_bn frozen\n",
      "47 conv5_block11_0_relu trainable\n",
      "48 conv5_block11_1_conv trainable\n",
      "49 conv5_block11_1_bn frozen\n",
      "50 conv5_block11_1_relu trainable\n",
      "51 conv5_block11_2_conv trainable\n",
      "52 conv5_block11_concat trainable\n",
      "53 conv5_block12_0_bn frozen\n",
      "54 conv5_block12_0_relu trainable\n",
      "55 conv5_block12_1_conv trainable\n",
      "56 conv5_block12_1_bn frozen\n",
      "57 conv5_block12_1_relu trainable\n",
      "58 conv5_block12_2_conv trainable\n",
      "59 conv5_block12_concat trainable\n",
      "60 conv5_block13_0_bn frozen\n",
      "61 conv5_block13_0_relu trainable\n",
      "62 conv5_block13_1_conv trainable\n",
      "63 conv5_block13_1_bn frozen\n",
      "64 conv5_block13_1_relu trainable\n",
      "65 conv5_block13_2_conv trainable\n",
      "66 conv5_block13_concat trainable\n",
      "67 conv5_block14_0_bn frozen\n",
      "68 conv5_block14_0_relu trainable\n",
      "69 conv5_block14_1_conv trainable\n",
      "70 conv5_block14_1_bn frozen\n",
      "71 conv5_block14_1_relu trainable\n",
      "72 conv5_block14_2_conv trainable\n",
      "73 conv5_block14_concat trainable\n",
      "74 conv5_block15_0_bn frozen\n",
      "75 conv5_block15_0_relu trainable\n",
      "76 conv5_block15_1_conv trainable\n",
      "77 conv5_block15_1_bn frozen\n",
      "78 conv5_block15_1_relu trainable\n",
      "79 conv5_block15_2_conv trainable\n",
      "80 conv5_block15_concat trainable\n",
      "81 conv5_block16_0_bn frozen\n",
      "82 conv5_block16_0_relu trainable\n",
      "83 conv5_block16_1_conv trainable\n",
      "84 conv5_block16_1_bn frozen\n",
      "85 conv5_block16_1_relu trainable\n",
      "86 conv5_block16_2_conv trainable\n",
      "87 conv5_block16_concat trainable\n",
      "88 bn frozen\n",
      "89 relu trainable\n",
      "Epoch 1/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 141ms/step - accuracy: 0.7611 - loss: 0.4954 - val_accuracy: 0.8700 - val_loss: 0.3337 - learning_rate: 2.0000e-05\n",
      "Epoch 2/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 111ms/step - accuracy: 0.8233 - loss: 0.3881 - val_accuracy: 0.9025 - val_loss: 0.2550 - learning_rate: 2.0000e-05\n",
      "Epoch 3/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.8726 - loss: 0.2966 - val_accuracy: 0.9255 - val_loss: 0.2012 - learning_rate: 2.0000e-05\n",
      "Epoch 4/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.9022 - loss: 0.2338 - val_accuracy: 0.9370 - val_loss: 0.1622 - learning_rate: 2.0000e-05\n",
      "Epoch 5/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9173 - loss: 0.2019 - val_accuracy: 0.9470 - val_loss: 0.1419 - learning_rate: 2.0000e-05\n",
      "Epoch 6/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9328 - loss: 0.1635 - val_accuracy: 0.9495 - val_loss: 0.1332 - learning_rate: 2.0000e-05\n",
      "Epoch 7/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9421 - loss: 0.1453 - val_accuracy: 0.9530 - val_loss: 0.1151 - learning_rate: 2.0000e-05\n",
      "Epoch 8/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.9538 - loss: 0.1227 - val_accuracy: 0.9580 - val_loss: 0.1124 - learning_rate: 2.0000e-05\n",
      "Epoch 9/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.9587 - loss: 0.1040 - val_accuracy: 0.9635 - val_loss: 0.0989 - learning_rate: 2.0000e-05\n",
      "Epoch 10/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9666 - loss: 0.0862 - val_accuracy: 0.9620 - val_loss: 0.0921 - learning_rate: 2.0000e-05\n",
      "Epoch 11/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9706 - loss: 0.0738 - val_accuracy: 0.9620 - val_loss: 0.0916 - learning_rate: 2.0000e-05\n",
      "Epoch 12/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 109ms/step - accuracy: 0.9790 - loss: 0.0604 - val_accuracy: 0.9625 - val_loss: 0.1053 - learning_rate: 2.0000e-05\n",
      "Epoch 13/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.9776 - loss: 0.0602 - val_accuracy: 0.9680 - val_loss: 0.0835 - learning_rate: 2.0000e-05\n",
      "Epoch 14/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9843 - loss: 0.0423 - val_accuracy: 0.9680 - val_loss: 0.0834 - learning_rate: 2.0000e-05\n",
      "Epoch 15/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9882 - loss: 0.0314\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9882 - loss: 0.0315 - val_accuracy: 0.9645 - val_loss: 0.1055 - learning_rate: 2.0000e-05\n",
      "Epoch 16/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9920 - loss: 0.0233 - val_accuracy: 0.9705 - val_loss: 0.0901 - learning_rate: 1.0000e-05\n",
      "Epoch 17/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9958 - loss: 0.0178\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 110ms/step - accuracy: 0.9957 - loss: 0.0178 - val_accuracy: 0.9725 - val_loss: 0.0889 - learning_rate: 1.0000e-05\n",
      "Epoch 18/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9941 - loss: 0.0164 - val_accuracy: 0.9725 - val_loss: 0.0908 - learning_rate: 5.0000e-06\n",
      "Epoch 19/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9960 - loss: 0.0131\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9960 - loss: 0.0131 - val_accuracy: 0.9715 - val_loss: 0.0923 - learning_rate: 5.0000e-06\n",
      "Epoch 20/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9966 - loss: 0.0119 - val_accuracy: 0.9695 - val_loss: 0.0922 - learning_rate: 2.5000e-06\n",
      "Epoch 21/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9946 - loss: 0.0139\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 109ms/step - accuracy: 0.9946 - loss: 0.0139 - val_accuracy: 0.9695 - val_loss: 0.0936 - learning_rate: 2.5000e-06\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9677 - loss: 0.0907\n",
      "\n",
      "[DenseNet121_finetuned] Test accuracy: 0.9685, Test loss: 0.0918\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 229ms/step\n",
      "\n",
      "Confusion matrix (DenseNet121):\n",
      "[[970  30]\n",
      " [ 33 967]]\n",
      "\n",
      "Classification report (DenseNet121):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.97      0.97      0.97      1000\n",
      "        real       0.97      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09182359278202057, 0.968500018119812)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# DenseNet121 – paper-style, tuned to reach ~97.3%\n",
    "# =======================\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 1) Preprocessing for DenseNet\n",
    "densenet_pre = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "# 2) Build generators (same as ResNet, just different preprocess func)\n",
    "train_den, val_den, test_den = build_generators(\n",
    "    TARGET_ROOT,\n",
    "    preprocess_func=densenet_pre\n",
    ")\n",
    "\n",
    "# 3) Base DenseNet121 backbone\n",
    "base_model_dense = DenseNet121(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Phase 1 – train new head only (8 epochs)\n",
    "# -------------------------\n",
    "base_model_dense.trainable = False  # freeze backbone\n",
    "\n",
    "inputs = layers.Input(shape=(256, 256, 3))\n",
    "x = base_model_dense(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)          # strong regularisation\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "densenet_model = models.Model(inputs, outputs, name=\"DenseNet121_model\")\n",
    "\n",
    "densenet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"=== Phase 1: DenseNet121 head training (8 epochs) ===\")\n",
    "densenet_model.summary()\n",
    "\n",
    "history_dense_p1, _ = train_and_evaluate_no_es(\n",
    "    densenet_model,\n",
    "    train_den,\n",
    "    val_den,\n",
    "    test_den,\n",
    "    epochs=8,\n",
    "    model_name=\"DenseNet121_phase1\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Phase 2 – more aggressive fine-tuning (up to 25 epochs)\n",
    "# -------------------------\n",
    "\n",
    "# Unfreeze a larger chunk: last ~80 layers (except BatchNorm)\n",
    "for layer in base_model_dense.layers[-80:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompile with lower LR for fine-tuning\n",
    "densenet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-5),  # slightly higher than 1e-5 for stronger adaptation\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Phase 2: Fine-tuning DenseNet121 (max 25 epochs) ===\")\n",
    "for i, layer in enumerate(base_model_dense.layers[-90:]):\n",
    "    print(i, layer.name, \"trainable\" if layer.trainable else \"frozen\")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=4,             # allow a bit more exploration\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_dense_p2 = densenet_model.fit(\n",
    "    train_den,\n",
    "    epochs=25,              # upper cap; EarlyStopping will stop earlier\n",
    "    validation_data=val_den,\n",
    "    callbacks=[early, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Final evaluation on test set\n",
    "# -------------------------\n",
    "test_loss_dense, test_acc_dense = densenet_model.evaluate(test_den, verbose=1)\n",
    "print(f\"\\n[DenseNet121_finetuned] Test accuracy: {test_acc_dense:.4f}, Test loss: {test_loss_dense:.4f}\")\n",
    "\n",
    "# Confusion matrix + classification report\n",
    "test_den.reset()\n",
    "preds_dense = densenet_model.predict(test_den, verbose=1)\n",
    "y_pred_dense = (preds_dense.ravel() >= 0.5).astype(int)\n",
    "y_true_dense = test_den.classes\n",
    "\n",
    "print(\"\\nConfusion matrix (DenseNet121):\")\n",
    "print(confusion_matrix(y_true_dense, y_pred_dense))\n",
    "\n",
    "print(\"\\nClassification report (DenseNet121):\")\n",
    "print(classification_report(y_true_dense, y_pred_dense, target_names=[\"fake\", \"real\"]))\n",
    "\n",
    "test_metrics_dense = (test_loss_dense, test_acc_dense)\n",
    "test_metrics_dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:33:13.385762Z",
     "iopub.status.busy": "2025-11-30T00:33:13.384984Z",
     "iopub.status.idle": "2025-11-30T00:50:06.043690Z",
     "shell.execute_reply": "2025-11-30T00:50:06.043015Z",
     "shell.execute_reply.started": "2025-11-30T00:33:13.385731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/3877290722.py:19: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_mobilenet = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV2_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV2_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,281\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,265\u001b[0m (8.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,225,153</span> (8.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,225,153\u001b[0m (8.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "E0000 00:00:1764462830.724499     139 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1764462830.863157     139 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 148ms/step - accuracy: 0.6217 - loss: 0.6683 - val_accuracy: 0.5360 - val_loss: 0.9154\n",
      "Epoch 2/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 135ms/step - accuracy: 0.8327 - loss: 0.3746 - val_accuracy: 0.7115 - val_loss: 0.5979\n",
      "Epoch 3/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.9156 - loss: 0.2116 - val_accuracy: 0.8935 - val_loss: 0.2572\n",
      "Epoch 4/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.9530 - loss: 0.1268 - val_accuracy: 0.9345 - val_loss: 0.1643\n",
      "Epoch 5/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 135ms/step - accuracy: 0.9733 - loss: 0.0793 - val_accuracy: 0.9605 - val_loss: 0.1061\n",
      "Epoch 6/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 135ms/step - accuracy: 0.9781 - loss: 0.0622 - val_accuracy: 0.9695 - val_loss: 0.0735\n",
      "Epoch 7/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.9883 - loss: 0.0395 - val_accuracy: 0.9685 - val_loss: 0.0822\n",
      "Epoch 8/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.9903 - loss: 0.0306 - val_accuracy: 0.9755 - val_loss: 0.0570\n",
      "Epoch 9/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 135ms/step - accuracy: 0.9940 - loss: 0.0217 - val_accuracy: 0.9770 - val_loss: 0.0574\n",
      "Epoch 10/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 135ms/step - accuracy: 0.9969 - loss: 0.0142 - val_accuracy: 0.9820 - val_loss: 0.0463\n",
      "Epoch 11/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 135ms/step - accuracy: 0.9971 - loss: 0.0127 - val_accuracy: 0.9775 - val_loss: 0.0540\n",
      "Epoch 12/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 135ms/step - accuracy: 0.9966 - loss: 0.0107 - val_accuracy: 0.9820 - val_loss: 0.0465\n",
      "Epoch 13/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 134ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.9825 - val_loss: 0.0449\n",
      "Epoch 14/14\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 135ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 0.9820 - val_loss: 0.0425\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9838 - loss: 0.0443\n",
      "\n",
      "[MobileNet_14epochs] Test accuracy: 0.9805, Test loss: 0.0475\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[986  14]\n",
      " [ 25 975]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.98      0.99      0.98      1000\n",
      "        real       0.99      0.97      0.98      1000\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04754861444234848, 0.9804999828338623)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# MobileNet – 14 epochs total (paper-style)\n",
    "# =======================\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1) Preprocessing for MobileNetV2 (scales to [-1, 1])\n",
    "mobilenet_pre = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# 2) Build generators for 20k_gan_8_1_1 using the same pipeline as other models\n",
    "train_mob, val_mob, test_mob = build_generators(\n",
    "    TARGET_ROOT,\n",
    "    preprocess_func=mobilenet_pre\n",
    ")\n",
    "\n",
    "# 3) Base MobileNetV2 backbone (no top)\n",
    "base_mobilenet = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# ⚠ Paper-style: train whole network for 14 epochs (no 2-phase scheme)\n",
    "base_mobilenet.trainable = True\n",
    "\n",
    "inputs = layers.Input(shape=(256, 256, 3))\n",
    "x = base_mobilenet(inputs, training=True)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)          # same regularisation style as other models\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "mobilenet_model = models.Model(inputs, outputs, name=\"MobileNetV2_model\")\n",
    "\n",
    "# Use a small LR since we're fine-tuning end-to-end from the start\n",
    "mobilenet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "mobilenet_model.summary()\n",
    "\n",
    "# 4) Train for EXACTLY 14 epochs (single phase)\n",
    "# train_and_evaluate_no_es should:\n",
    "#   - fit() for 'epochs' epochs\n",
    "#   - evaluate on test set\n",
    "#   - optionally print confusion matrix & classification report\n",
    "history_mob, test_metrics_mob = train_and_evaluate_no_es(\n",
    "    mobilenet_model,\n",
    "    train_mob,\n",
    "    val_mob,\n",
    "    test_mob,\n",
    "    epochs=14,                 # 👉 paper’s epoch count\n",
    "    model_name=\"MobileNet_14epochs\"\n",
    ")\n",
    "\n",
    "test_metrics_mob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T02:12:46.733044Z",
     "iopub.status.busy": "2025-11-30T02:12:46.732083Z",
     "iopub.status.idle": "2025-11-30T02:12:47.213982Z",
     "shell.execute_reply": "2025-11-30T02:12:47.213382Z",
     "shell.execute_reply.started": "2025-11-30T02:12:46.733015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "mobilenet_model.save(\"mobilenet_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:50:30.857215Z",
     "iopub.status.busy": "2025-11-30T00:50:30.856399Z",
     "iopub.status.idle": "2025-11-30T00:50:31.062063Z",
     "shell.execute_reply": "2025-11-30T00:50:31.061496Z",
     "shell.execute_reply.started": "2025-11-30T00:50:30.857187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "16000 train images\n",
      "2000 val images\n",
      "2000 test images\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 1: Imports + generators for InceptionV3\n",
    "# =======================\n",
    "\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "# InceptionV3 expects inputs scaled to [-1, 1]\n",
    "inception_pre = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "# Use your existing helper to build train/val/test generators\n",
    "train_inc, val_inc, test_inc = build_generators(\n",
    "    TARGET_ROOT,\n",
    "    preprocess_func=inception_pre\n",
    ")\n",
    "\n",
    "print(train_inc.samples, \"train images\")\n",
    "print(val_inc.samples, \"val images\")\n",
    "print(test_inc.samples, \"test images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:50:35.333235Z",
     "iopub.status.busy": "2025-11-30T00:50:35.332608Z",
     "iopub.status.idle": "2025-11-30T00:57:39.620767Z",
     "shell.execute_reply": "2025-11-30T00:57:39.619807Z",
     "shell.execute_reply.started": "2025-11-30T00:50:35.333212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "=== Phase 1: InceptionV3 head training (8 epochs) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"InceptionV3_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"InceptionV3_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m2,049\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,804,833</span> (83.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,804,833\u001b[0m (83.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> (8.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,049\u001b[0m (8.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> (83.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,802,784\u001b[0m (83.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 117ms/step - accuracy: 0.6072 - loss: 0.6690 - val_accuracy: 0.7150 - val_loss: 0.5606\n",
      "Epoch 2/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - accuracy: 0.6982 - loss: 0.5780 - val_accuracy: 0.7375 - val_loss: 0.5335\n",
      "Epoch 3/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 93ms/step - accuracy: 0.7097 - loss: 0.5620 - val_accuracy: 0.7395 - val_loss: 0.5318\n",
      "Epoch 4/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - accuracy: 0.7258 - loss: 0.5441 - val_accuracy: 0.7575 - val_loss: 0.5025\n",
      "Epoch 5/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 93ms/step - accuracy: 0.7281 - loss: 0.5457 - val_accuracy: 0.7570 - val_loss: 0.5041\n",
      "Epoch 6/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - accuracy: 0.7304 - loss: 0.5432 - val_accuracy: 0.7605 - val_loss: 0.4995\n",
      "Epoch 7/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - accuracy: 0.7241 - loss: 0.5395 - val_accuracy: 0.7420 - val_loss: 0.5237\n",
      "Epoch 8/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 93ms/step - accuracy: 0.7274 - loss: 0.5397 - val_accuracy: 0.7575 - val_loss: 0.4990\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8100 - loss: 0.4618\n",
      "\n",
      "[InceptionV3_phase1] Test accuracy: 0.7740, Test loss: 0.4835\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 167ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[834 166]\n",
      " [286 714]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.74      0.83      0.79      1000\n",
      "        real       0.81      0.71      0.76      1000\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.78      0.77      0.77      2000\n",
      "weighted avg       0.78      0.77      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 2: InceptionV3 – build model & Phase 1 (head only, 8 epochs)\n",
    "# =======================\n",
    "\n",
    "# 1) Base InceptionV3 (no top)\n",
    "base_inception = InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Phase 1: freeze backbone, train only new head\n",
    "base_inception.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(256, 256, 3))\n",
    "x = base_inception(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)            # regularization similar to paper-style\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "inception_model = models.Model(inputs, outputs, name=\"InceptionV3_model\")\n",
    "\n",
    "# Slightly higher LR since only the head is trainable\n",
    "inception_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"=== Phase 1: InceptionV3 head training (8 epochs) ===\")\n",
    "inception_model.summary()\n",
    "\n",
    "# Train head for 8 epochs\n",
    "history_inc_p1, _ = train_and_evaluate_no_es(\n",
    "    inception_model,\n",
    "    train_inc,\n",
    "    val_inc,\n",
    "    test_inc,\n",
    "    epochs=8,                # Phase 1: 8 epochs\n",
    "    model_name=\"InceptionV3_phase1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:58:25.251948Z",
     "iopub.status.busy": "2025-11-30T00:58:25.251674Z",
     "iopub.status.idle": "2025-11-30T01:26:44.588438Z",
     "shell.execute_reply": "2025-11-30T01:26:44.587821Z",
     "shell.execute_reply.started": "2025-11-30T00:58:25.251928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase 2: Fine-tuning InceptionV3 (max 26 epochs) ===\n",
      "0 batch_normalization_63 frozen\n",
      "1 batch_normalization_68 frozen\n",
      "2 batch_normalization_69 frozen\n",
      "3 activation_60 frozen\n",
      "4 activation_63 frozen\n",
      "5 activation_68 frozen\n",
      "6 activation_69 frozen\n",
      "7 mixed7 frozen\n",
      "8 conv2d_74 frozen\n",
      "9 batch_normalization_72 frozen\n",
      "10 activation_72 trainable\n",
      "11 conv2d_75 trainable\n",
      "12 batch_normalization_73 frozen\n",
      "13 activation_73 trainable\n",
      "14 conv2d_72 trainable\n",
      "15 conv2d_76 trainable\n",
      "16 batch_normalization_70 frozen\n",
      "17 batch_normalization_74 frozen\n",
      "18 activation_70 trainable\n",
      "19 activation_74 trainable\n",
      "20 conv2d_73 trainable\n",
      "21 conv2d_77 trainable\n",
      "22 batch_normalization_71 frozen\n",
      "23 batch_normalization_75 frozen\n",
      "24 activation_71 trainable\n",
      "25 activation_75 trainable\n",
      "26 max_pooling2d_5 trainable\n",
      "27 mixed8 trainable\n",
      "28 conv2d_82 trainable\n",
      "29 batch_normalization_80 frozen\n",
      "30 activation_80 trainable\n",
      "31 conv2d_79 trainable\n",
      "32 conv2d_83 trainable\n",
      "33 batch_normalization_77 frozen\n",
      "34 batch_normalization_81 frozen\n",
      "35 activation_77 trainable\n",
      "36 activation_81 trainable\n",
      "37 conv2d_80 trainable\n",
      "38 conv2d_81 trainable\n",
      "39 conv2d_84 trainable\n",
      "40 conv2d_85 trainable\n",
      "41 average_pooling2d_7 trainable\n",
      "42 conv2d_78 trainable\n",
      "43 batch_normalization_78 frozen\n",
      "44 batch_normalization_79 frozen\n",
      "45 batch_normalization_82 frozen\n",
      "46 batch_normalization_83 frozen\n",
      "47 conv2d_86 trainable\n",
      "48 batch_normalization_76 frozen\n",
      "49 activation_78 trainable\n",
      "50 activation_79 trainable\n",
      "51 activation_82 trainable\n",
      "52 activation_83 trainable\n",
      "53 batch_normalization_84 frozen\n",
      "54 activation_76 trainable\n",
      "55 mixed9_0 trainable\n",
      "56 concatenate trainable\n",
      "57 activation_84 trainable\n",
      "58 mixed9 trainable\n",
      "59 conv2d_91 trainable\n",
      "60 batch_normalization_89 frozen\n",
      "61 activation_89 trainable\n",
      "62 conv2d_88 trainable\n",
      "63 conv2d_92 trainable\n",
      "64 batch_normalization_86 frozen\n",
      "65 batch_normalization_90 frozen\n",
      "66 activation_86 trainable\n",
      "67 activation_90 trainable\n",
      "68 conv2d_89 trainable\n",
      "69 conv2d_90 trainable\n",
      "70 conv2d_93 trainable\n",
      "71 conv2d_94 trainable\n",
      "72 average_pooling2d_8 trainable\n",
      "73 conv2d_87 trainable\n",
      "74 batch_normalization_87 frozen\n",
      "75 batch_normalization_88 frozen\n",
      "76 batch_normalization_91 frozen\n",
      "77 batch_normalization_92 frozen\n",
      "78 conv2d_95 trainable\n",
      "79 batch_normalization_85 frozen\n",
      "80 activation_87 trainable\n",
      "81 activation_88 trainable\n",
      "82 activation_91 trainable\n",
      "83 activation_92 trainable\n",
      "84 batch_normalization_93 frozen\n",
      "85 activation_85 trainable\n",
      "86 mixed9_1 trainable\n",
      "87 concatenate_1 trainable\n",
      "88 activation_93 trainable\n",
      "89 mixed10 trainable\n",
      "Epoch 1/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 144ms/step - accuracy: 0.7998 - loss: 0.4312 - val_accuracy: 0.8495 - val_loss: 0.3434\n",
      "Epoch 2/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - accuracy: 0.8863 - loss: 0.2704 - val_accuracy: 0.8805 - val_loss: 0.2938\n",
      "Epoch 3/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - accuracy: 0.9330 - loss: 0.1682 - val_accuracy: 0.8995 - val_loss: 0.2488\n",
      "Epoch 4/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - accuracy: 0.9631 - loss: 0.0994 - val_accuracy: 0.8950 - val_loss: 0.2826\n",
      "Epoch 5/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9811 - loss: 0.0562 - val_accuracy: 0.9090 - val_loss: 0.2600\n",
      "Epoch 6/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9910 - loss: 0.0288 - val_accuracy: 0.9040 - val_loss: 0.2852\n",
      "Epoch 7/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9958 - loss: 0.0182 - val_accuracy: 0.9015 - val_loss: 0.3739\n",
      "Epoch 8/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9974 - loss: 0.0105 - val_accuracy: 0.9100 - val_loss: 0.3055\n",
      "Epoch 9/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9984 - loss: 0.0076 - val_accuracy: 0.9125 - val_loss: 0.3281\n",
      "Epoch 10/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.9150 - val_loss: 0.3448\n",
      "Epoch 11/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9979 - loss: 0.0078 - val_accuracy: 0.9125 - val_loss: 0.2997\n",
      "Epoch 12/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9983 - loss: 0.0060 - val_accuracy: 0.9135 - val_loss: 0.3150\n",
      "Epoch 13/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9989 - loss: 0.0040 - val_accuracy: 0.9115 - val_loss: 0.3771\n",
      "Epoch 14/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9966 - loss: 0.0084 - val_accuracy: 0.9190 - val_loss: 0.3451\n",
      "Epoch 15/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9205 - val_loss: 0.3859\n",
      "Epoch 16/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9999 - loss: 9.7472e-04 - val_accuracy: 0.9105 - val_loss: 0.4275\n",
      "Epoch 17/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9225 - val_loss: 0.3916\n",
      "Epoch 18/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9110 - val_loss: 0.4079\n",
      "Epoch 19/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9942 - loss: 0.0171 - val_accuracy: 0.9230 - val_loss: 0.3565\n",
      "Epoch 20/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9180 - val_loss: 0.4141\n",
      "Epoch 21/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 3.6347e-04 - val_accuracy: 0.9200 - val_loss: 0.4189\n",
      "Epoch 22/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9205 - val_loss: 0.3322\n",
      "Epoch 23/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 127ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9230 - val_loss: 0.3756\n",
      "Epoch 24/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 8.4927e-04 - val_accuracy: 0.9185 - val_loss: 0.4240\n",
      "Epoch 25/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 0.9943 - loss: 0.0190 - val_accuracy: 0.9230 - val_loss: 0.3689\n",
      "Epoch 26/26\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 4.9100e-04 - val_accuracy: 0.9235 - val_loss: 0.3749\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.9358 - loss: 0.3153\n",
      "\n",
      "[InceptionV3_finetuned] Test accuracy: 0.9330, Test loss: 0.3509\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step\n",
      "\n",
      "Confusion matrix:\n",
      "[[934  66]\n",
      " [ 68 932]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.93      0.93      1000\n",
      "        real       0.93      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.93      0.93      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35085606575012207, 0.9330000281333923)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# Cell 3: InceptionV3 – Phase 2 fine-tuning (26 epochs, total 34)\n",
    "# =======================\n",
    "\n",
    "# Unfreeze top part of the InceptionV3 backbone for fine-tuning\n",
    "# We keep BatchNorm layers frozen for stability.\n",
    "for layer in base_inception.layers[-80:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompile with a much smaller learning rate for fine-tuning\n",
    "inception_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Phase 2: Fine-tuning InceptionV3 (max 26 epochs) ===\")\n",
    "for i, layer in enumerate(base_inception.layers[-90:]):\n",
    "    print(i, layer.name, \"trainable\" if layer.trainable else \"frozen\")\n",
    "\n",
    "# Now train for up to 26 more epochs → 8 + 26 = 34 total (paper)\n",
    "history_inc_p2, test_metrics_inception = train_and_evaluate_no_es(\n",
    "    inception_model,\n",
    "    train_inc,\n",
    "    val_inc,\n",
    "    test_inc,\n",
    "    epochs=26,               # Phase 2: 26 epochs → 34 total\n",
    "    model_name=\"InceptionV3_finetuned\"\n",
    ")\n",
    "\n",
    "test_metrics_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T02:25:10.779947Z",
     "iopub.status.busy": "2025-11-30T02:25:10.779452Z",
     "iopub.status.idle": "2025-11-30T02:25:10.959481Z",
     "shell.execute_reply": "2025-11-30T02:25:10.958934Z",
     "shell.execute_reply.started": "2025-11-30T02:25:10.779926Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# DATA GENERATORS FOR CNN MODEL\n",
    "# ============================\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image size (paper uses 256×256 for all models)\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    TARGET_ROOT / \"train\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    TARGET_ROOT / \"val\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    TARGET_ROOT / \"test\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T02:25:18.948567Z",
     "iopub.status.busy": "2025-11-30T02:25:18.947775Z",
     "iopub.status.idle": "2025-11-30T02:25:19.058655Z",
     "shell.execute_reply": "2025-11-30T02:25:19.057850Z",
     "shell.execute_reply.started": "2025-11-30T02:25:18.948539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CustomCNN_l2_bn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CustomCNN_l2_bn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_99          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_103         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_21 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_102 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_99          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_99 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_103 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_100 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_104 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_101 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_105 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_102 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m16,777,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_103         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_103 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,169,089</span> (65.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,169,089\u001b[0m (65.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,167,617</span> (65.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,167,617\u001b[0m (65.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
    "\n",
    "weight_decay = 1e-4\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "def build_custom_cnn():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(\n",
    "        32, (3, 3), padding=\"same\",\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(\n",
    "        64, (3, 3), padding=\"same\",\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(\n",
    "        128, (3, 3), padding=\"same\",\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(\n",
    "        256, (3, 3), padding=\"same\",\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # You can add a 5th block if you want slightly more capacity:\n",
    "    # x = layers.Conv2D(\n",
    "    #     256, (3, 3), padding=\"same\",\n",
    "    #     kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    # )(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    # x = layers.Activation(\"relu\")(x)\n",
    "    # x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Classifier head\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Dropout(0.6)(x)   # stronger dropout than before\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"CustomCNN_l2_bn\")\n",
    "    return model\n",
    "\n",
    "custom_cnn = build_custom_cnn()\n",
    "custom_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T02:25:22.472803Z",
     "iopub.status.busy": "2025-11-30T02:25:22.472531Z",
     "iopub.status.idle": "2025-11-30T04:54:29.605222Z",
     "shell.execute_reply": "2025-11-30T04:54:29.604416Z",
     "shell.execute_reply.started": "2025-11-30T02:25:22.472783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 451ms/step - accuracy: 0.6170 - loss: 0.8885 - val_accuracy: 0.6685 - val_loss: 0.7094 - learning_rate: 5.0000e-05\n",
      "Epoch 2/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.6887 - loss: 0.7123 - val_accuracy: 0.6730 - val_loss: 0.7672 - learning_rate: 5.0000e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 443ms/step - accuracy: 0.7218 - loss: 0.6575 - val_accuracy: 0.7695 - val_loss: 0.5637 - learning_rate: 5.0000e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 444ms/step - accuracy: 0.7594 - loss: 0.5972 - val_accuracy: 0.7725 - val_loss: 0.5712 - learning_rate: 5.0000e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 443ms/step - accuracy: 0.7675 - loss: 0.5750 - val_accuracy: 0.7410 - val_loss: 0.6546 - learning_rate: 5.0000e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 443ms/step - accuracy: 0.7828 - loss: 0.5558 - val_accuracy: 0.7930 - val_loss: 0.5233 - learning_rate: 5.0000e-05\n",
      "Epoch 7/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 442ms/step - accuracy: 0.7943 - loss: 0.5301 - val_accuracy: 0.8190 - val_loss: 0.5009 - learning_rate: 5.0000e-05\n",
      "Epoch 8/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 441ms/step - accuracy: 0.8094 - loss: 0.4997 - val_accuracy: 0.8020 - val_loss: 0.5047 - learning_rate: 5.0000e-05\n",
      "Epoch 9/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 449ms/step - accuracy: 0.8216 - loss: 0.4821 - val_accuracy: 0.8280 - val_loss: 0.4623 - learning_rate: 5.0000e-05\n",
      "Epoch 10/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 446ms/step - accuracy: 0.8302 - loss: 0.4577 - val_accuracy: 0.7985 - val_loss: 0.5476 - learning_rate: 5.0000e-05\n",
      "Epoch 11/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 442ms/step - accuracy: 0.8404 - loss: 0.4545 - val_accuracy: 0.8385 - val_loss: 0.4553 - learning_rate: 5.0000e-05\n",
      "Epoch 12/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 444ms/step - accuracy: 0.8461 - loss: 0.4319 - val_accuracy: 0.8565 - val_loss: 0.4242 - learning_rate: 5.0000e-05\n",
      "Epoch 13/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 444ms/step - accuracy: 0.8495 - loss: 0.4297 - val_accuracy: 0.7775 - val_loss: 0.5758 - learning_rate: 5.0000e-05\n",
      "Epoch 14/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 447ms/step - accuracy: 0.8670 - loss: 0.4004 - val_accuracy: 0.8460 - val_loss: 0.4321 - learning_rate: 5.0000e-05\n",
      "Epoch 15/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 448ms/step - accuracy: 0.8703 - loss: 0.3994 - val_accuracy: 0.8280 - val_loss: 0.4744 - learning_rate: 5.0000e-05\n",
      "Epoch 16/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 446ms/step - accuracy: 0.8706 - loss: 0.3985 - val_accuracy: 0.8630 - val_loss: 0.4168 - learning_rate: 5.0000e-05\n",
      "Epoch 17/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 449ms/step - accuracy: 0.8746 - loss: 0.3831 - val_accuracy: 0.8580 - val_loss: 0.4239 - learning_rate: 5.0000e-05\n",
      "Epoch 18/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.8863 - loss: 0.3616 - val_accuracy: 0.8865 - val_loss: 0.3763 - learning_rate: 5.0000e-05\n",
      "Epoch 19/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 441ms/step - accuracy: 0.8907 - loss: 0.3568 - val_accuracy: 0.8570 - val_loss: 0.4234 - learning_rate: 5.0000e-05\n",
      "Epoch 20/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.8979 - loss: 0.3480 - val_accuracy: 0.8785 - val_loss: 0.3871 - learning_rate: 5.0000e-05\n",
      "Epoch 21/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 454ms/step - accuracy: 0.8986 - loss: 0.3444 - val_accuracy: 0.8405 - val_loss: 0.4870 - learning_rate: 5.0000e-05\n",
      "Epoch 22/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.9021 - loss: 0.3389\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 445ms/step - accuracy: 0.9021 - loss: 0.3389 - val_accuracy: 0.7895 - val_loss: 0.5947 - learning_rate: 5.0000e-05\n",
      "Epoch 23/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 441ms/step - accuracy: 0.9113 - loss: 0.3095 - val_accuracy: 0.8905 - val_loss: 0.3545 - learning_rate: 2.5000e-05\n",
      "Epoch 24/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 446ms/step - accuracy: 0.9184 - loss: 0.2984 - val_accuracy: 0.8935 - val_loss: 0.3486 - learning_rate: 2.5000e-05\n",
      "Epoch 25/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 442ms/step - accuracy: 0.9195 - loss: 0.2966 - val_accuracy: 0.8920 - val_loss: 0.3656 - learning_rate: 2.5000e-05\n",
      "Epoch 26/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 449ms/step - accuracy: 0.9246 - loss: 0.2837 - val_accuracy: 0.9025 - val_loss: 0.3378 - learning_rate: 2.5000e-05\n",
      "Epoch 27/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 448ms/step - accuracy: 0.9269 - loss: 0.2758 - val_accuracy: 0.8900 - val_loss: 0.3556 - learning_rate: 2.5000e-05\n",
      "Epoch 28/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 448ms/step - accuracy: 0.9273 - loss: 0.2753 - val_accuracy: 0.8815 - val_loss: 0.3909 - learning_rate: 2.5000e-05\n",
      "Epoch 29/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.9307 - loss: 0.2683 - val_accuracy: 0.8930 - val_loss: 0.3514 - learning_rate: 2.5000e-05\n",
      "Epoch 30/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 449ms/step - accuracy: 0.9330 - loss: 0.2630 - val_accuracy: 0.9005 - val_loss: 0.3314 - learning_rate: 2.5000e-05\n",
      "Epoch 31/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 450ms/step - accuracy: 0.9366 - loss: 0.2611 - val_accuracy: 0.8865 - val_loss: 0.3649 - learning_rate: 2.5000e-05\n",
      "Epoch 32/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 449ms/step - accuracy: 0.9336 - loss: 0.2599 - val_accuracy: 0.8990 - val_loss: 0.3389 - learning_rate: 2.5000e-05\n",
      "Epoch 33/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 450ms/step - accuracy: 0.9394 - loss: 0.2514 - val_accuracy: 0.8820 - val_loss: 0.3911 - learning_rate: 2.5000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.9437 - loss: 0.2467\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 458ms/step - accuracy: 0.9437 - loss: 0.2467 - val_accuracy: 0.9020 - val_loss: 0.3348 - learning_rate: 2.5000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 446ms/step - accuracy: 0.9428 - loss: 0.2393 - val_accuracy: 0.9115 - val_loss: 0.3205 - learning_rate: 1.2500e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 448ms/step - accuracy: 0.9483 - loss: 0.2294 - val_accuracy: 0.9105 - val_loss: 0.3200 - learning_rate: 1.2500e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 453ms/step - accuracy: 0.9497 - loss: 0.2241 - val_accuracy: 0.8965 - val_loss: 0.3498 - learning_rate: 1.2500e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 447ms/step - accuracy: 0.9558 - loss: 0.2207 - val_accuracy: 0.9055 - val_loss: 0.3167 - learning_rate: 1.2500e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.9562 - loss: 0.2155 - val_accuracy: 0.9105 - val_loss: 0.3242 - learning_rate: 1.2500e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 445ms/step - accuracy: 0.9531 - loss: 0.2147 - val_accuracy: 0.9135 - val_loss: 0.3036 - learning_rate: 1.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    }
   ],
   "source": [
    "# Compile with a slightly smaller LR\n",
    "custom_cnn.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_cnn = custom_cnn.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=40,                 # max 40 like we discussed\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T04:57:41.872237Z",
     "iopub.status.busy": "2025-11-30T04:57:41.871333Z",
     "iopub.status.idle": "2025-11-30T04:57:46.227953Z",
     "shell.execute_reply": "2025-11-30T04:57:46.227123Z",
     "shell.execute_reply.started": "2025-11-30T04:57:41.872199Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step\n",
      "Confusion matrix:\n",
      "[[933  67]\n",
      " [ 74 926]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.93      0.93      1000\n",
      "        real       0.93      0.93      0.93      1000\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.93      0.93      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "test_gen.reset()\n",
    "y_prob = custom_cnn.predict(test_gen, verbose=1).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "y_true = test_gen.classes  # assumes standard Keras generator\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"fake\", \"real\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 501529,
     "sourceId": 939937,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
